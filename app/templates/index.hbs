<section>
  <h2>Purpose</h2>
  <p>The purpose of this website is to track the ways in which an application can have automated accessibility(a11y) linting and automated a11y testing, and provide the ways an application could fail global digital accessibility standards in a detailed way. From the perspective of engineers who wish to build automated tooling, it is not useful to merely track a success criteria, since a single success criteria could have multiple points of failure.</p>
  <p>The information found on this site intends to itemize the ways that applications could have accessibility errors. Each detail page will provide a summary view that covers four different things: automated linting, automated testing, developer authored tests, and manual testing. It will also provide more detailed prose for each of these items, which should provide context for each (either how-to, or addressing the limitations that currently exist).</p>
</section>
<section>
  <h2>Summary Numbers</h2>
  <p><em>This section is a work in progress.</em></p>
  <p>Currently, we count 272 ways an application could fail digital accessibility criteria, but suspect this number will increase as this application matures. These itemized details were pulled from WCAG, EN 301 549, and Section 508.</p>
  <p><strong>Of these 272 potential failures, initial analysis has indicated that 159 of them are either already automated or are potentially automatable.</strong> This means that 113 of them still require manual testing, until such time as technology sufficiently advances to programmatically determine such items.</p>
  <p>For each detail page, we will attempt to address the potential ways a failure item could be tested- through linting, testing, developer-authored tests, or manual tests. We will provide a current status for each item, and attempt to provide analysis for each item, as well as instructions for manually testing any item.</p>

</section>
